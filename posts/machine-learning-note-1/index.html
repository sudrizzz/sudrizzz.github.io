<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content='《机器学习》笔记系列文章内容按照《机器学习》书本章节进行排布，节号与书中节号一一对应。 1 绪论 1.2 基本术语 术语 英语原意 释义 数据集 data set 一组关于一个'><title>《机器学习》笔记（第一、二章）</title>
<link rel=canonical href=https://jinggqu.github.io/posts/machine-learning-note-1/><link rel=stylesheet href=/scss/style.min.abbd69b2908fdfcd5179898beaafd374514a86538d81639ddd2c58c06ae54e40.css><meta property='og:title' content='《机器学习》笔记（第一、二章）'><meta property='og:description' content='《机器学习》笔记系列文章内容按照《机器学习》书本章节进行排布，节号与书中节号一一对应。 1 绪论 1.2 基本术语 术语 英语原意 释义 数据集 data set 一组关于一个'><meta property='og:url' content='https://jinggqu.github.io/posts/machine-learning-note-1/'><meta property='og:site_name' content="Anthony's blog"><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:published_time' content='2020-12-22T09:00:00+08:00'><meta property='article:modified_time' content='2020-12-22T09:00:00+08:00'><meta name=twitter:title content="《机器学习》笔记（第一、二章）"><meta name=twitter:description content="《机器学习》笔记系列文章内容按照《机器学习》书本章节进行排布，节号与书中节号一一对应。 1 绪论 1.2 基本术语 术语 英语原意 释义 数据集 data set 一组关于一个"></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/avatar_hu21404bcd31e1a086eb11a4f61fea96c8_202717_300x0_resize_box_3.png width=300 height=300 class=site-logo loading=lazy alt=Avatar></a></figure><div class=site-meta><h1 class=site-name><a href=/>Anthony's blog</a></h1><h2 class=site-description></h2></div></header><ol class=menu id=main-menu><li><a href=/><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/archives><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li><a href=/search><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li><a href=https://github.com/jinggqu target=_blank><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg>
<span>GitHub</span></a></li><div class=menu-bottom-section><li id=i18n-switch><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-language" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M4 5h7"/><path d="M9 3v2c0 4.418-2.239 8-5 8"/><path d="M5 9c-.003 2.144 2.952 3.908 6.7 4"/><path d="M12 20l4-9 4 9"/><path d="M19.1 18h-6.2"/></svg>
<select name=language onchange="window.location.href=this.selectedOptions[0].value"><option value=https://jinggqu.github.io/ selected></option></select></li><li id=dark-mode-toggle><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>Dark Mode</span></li></div></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">Table of contents</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#1-绪论>1 绪论</a><ol><li><a href=#12-基本术语>1.2 基本术语</a></li></ol></li><li><a href=#2-模型评估与选择>2 模型评估与选择</a><ol><li><a href=#21-经验误差与过拟合>2.1 经验误差与过拟合</a><ol><li><a href=#误差>误差</a></li><li><a href=#过拟合与欠拟合>过拟合与欠拟合</a></li></ol></li><li><a href=#22-评估方法>2.2 评估方法</a><ol><li><a href=#221-留出法>2.2.1 留出法</a></li><li><a href=#222-交叉验证法>2.2.2 交叉验证法</a></li><li><a href=#223-自助法>2.2.3 自助法</a></li></ol></li><li><a href=#23-性能度量>2.3 性能度量</a><ol><li><a href=#231-错误率与精度>2.3.1 错误率与精度</a></li><li><a href=#232-查准率查全率与-f1-度量>2.3.2 查准率、查全率与 F1 度量</a></li><li><a href=#233-roc-与-auc>2.3.3 ROC 与 AUC</a></li><li><a href=#234-代价敏感错误率与代价曲线>2.3.4 代价敏感错误率与代价曲线</a></li></ol></li></ol></li><li><a href=#参考文献>参考文献</a></li></ol></nav></div></section></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><header class=article-category><a href=/categories/machine-learning/>Machine-Learning</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/posts/machine-learning-note-1/>《机器学习》笔记（第一、二章）</a></h2></div><footer class=article-time><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Dec 22, 2020</time></div><div><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>10 minute read</time></div></footer></div></header><section class=article-content><p>《机器学习》笔记系列文章内容按照《机器学习》书本章节进行排布，节号与书中节号一一对应。</p><h1 id=1-绪论>1 绪论</h1><h2 id=12-基本术语>1.2 基本术语</h2><div class=table-wrapper><table><thead><tr><th>术语</th><th>英语原意</th><th>释义</th></tr></thead><tbody><tr><td>数据集</td><td>data set</td><td>一组关于一个事件或对象的描述的集合</td></tr><tr><td>样本 / 示例</td><td>sample / instance</td><td>数据集中的每条记录</td></tr><tr><td>属性 / 特征</td><td>attribute / feature</td><td>反映样本在某方面的表现或性质的事项</td></tr><tr><td>训练数据</td><td>training data</td><td>用于训练的数据</td></tr><tr><td>训练样本</td><td>training sample</td><td>训练数据中的每个样本</td></tr><tr><td>假设</td><td>hypothesis</td><td>通过训练学得数据的某种规律</td></tr><tr><td>真实</td><td>ground-truth</td><td>潜在规律本身</td></tr><tr><td>预测</td><td>prediction</td><td>训练结果生成的模型</td></tr><tr><td>分类</td><td>classification</td><td>预测离散值</td></tr><tr><td>二分类</td><td>binary classification</td><td>只涉及两个特征的分类</td></tr><tr><td>多分类</td><td>multi-class classification</td><td>涉及多个特征的分类</td></tr><tr><td>回归</td><td>regression</td><td>预测连续值</td></tr><tr><td>聚类</td><td>clustering</td><td>对训练样本进行分组</td></tr><tr><td>簇</td><td>cluster</td><td>聚类后的每一个组</td></tr><tr><td>监督学习</td><td>supervised learning</td><td>训练数据有标记信息的训练（分类与回归）</td></tr><tr><td>无监督学习</td><td>unsupervised learning</td><td>训练数据没有标记信息的训练（聚类）</td></tr></tbody></table></div><h1 id=2-模型评估与选择>2 模型评估与选择</h1><h2 id=21-经验误差与过拟合>2.1 经验误差与过拟合</h2><h3 id=误差>误差</h3><p>通常我们把分类错误的样本数占样本总数的比例称为“错误率”（error rate），即如果在 m 个样本中有 a 个样本分类错误，则错误率 $ E = \frac{a}{m} $； 相应的，$ 1 - \frac{a}{m} $ 称为“精度”（accuracy），即“精度 = 1 - 错误率”。</p><p>更一般地，我们把学习器的实际预测输出与样本的真实输出之间的差异称为“误差”（error），学习器在训练集上的误差称为”训练误差“（training error） 或“经验误差”（empirical error）, 在新样本上的误差称为“泛化误差”（generalization errorr）。</p><h3 id=过拟合与欠拟合>过拟合与欠拟合</h3><p>为了达到更好的学习效果，应该从训练样本中尽可能学出适用于所有潜在样本的“普遍规律”，这样才能在遇到新样本时做出正确的判别。然而，当学习器把训练样本学得“太好”了的时候，很可能已经把训练样本自身的一些特点当作了所有潜在样本都会具有的一般性质，这样就会导致泛化性能下降。这种现象在机器学习中称为“过拟合”（overfitting）。 与“过拟合”相对的是“欠拟合”（underfitting），这是指对训练样本的一般性质尚未学好。</p><p>下图展示了欠拟合与过拟合，蓝色点为训练数据，橙色点为测试数据，红色曲线为拟合曲线。</p><p>最优拟合
<img src=https://cdn.jsdelivr.net/gh/jinggqu/blog_images@main/20201222151854.png loading=lazy alt=20201222151854></p><p>欠拟合（underfitting）
<img src=https://cdn.jsdelivr.net/gh/jinggqu/blog_images@main/20201222153133.png loading=lazy alt=20201222153133></p><p>过拟合（overfitting）
<img src=https://cdn.jsdelivr.net/gh/jinggqu/blog_images@main/20201222152022.png loading=lazy alt=20201222152022></p><p>过拟合的训练误差（蓝色）与泛化误差（红色）
<img src=https://cdn.jsdelivr.net/gh/jinggqu/blog_images@main/20201222152706.png loading=lazy alt=20201222152706></p><h2 id=22-评估方法>2.2 评估方法</h2><h3 id=221-留出法>2.2.1 留出法</h3><p>留出法（hold-out）直接将数据集 $D$ 划分为两个互斥的集合，其中一个集合作为训练集 $S$，另一个作为测试集 $T$，即</p><p>$$ D = S \cup T , S \cap T=\varnothing $$</p><p>需要注意的是训练/测试集的划分要尽可能保持数据分布的一致性，避免因数据划分过程引入额外的偏差而对最终结果产生影响。</p><h3 id=222-交叉验证法>2.2.2 交叉验证法</h3><p>交叉验证法（cross validation）先将数据集 $D$ 划分为 $k$ 个大小相似的互斥子集，即</p><p>$$ D = D_1 \cup D_2 \cup \dots \cup D_k , D_i \cap D_j = \varnothing (i \ne j)$$</p><p>每个子集 $D_{i}$ 都尽可能保持数据分布的一致性，即从 $D$ 中通过分层采样得到。然后每次用 $k - 1$ 个子集的并集作为训练集，余下的那个子集作为测试集；这样就可以获得 $k$ 组训练/测试集，从而可进行 $k$ 次训练和测试，最终返回的是这 $k$ 个测试结果得得得均值。显然，交叉验证法评估结果的稳定性和保真性在很大程度上取决于 $k$ 的取值，为强调这一点，通常把交叉验证法称为 ”$k$ 折交叉验证“（$k$-fold cross validation）。$k$ 最常用的取值是 10，此时成为 10 折交叉验证。下图为 10 折交叉验证的示意图。</p><p><img src=https://cdn.jsdelivr.net/gh/jinggqu/blog_images@main/20201222174250.png loading=lazy alt=20201222174250></p><p>假定数据集 $D$ 中包含 $m$ 个样本，令 $k=m$，则得到了交叉验证法的一个特例：留一法（Leave-One-Out，简称 LOO）。显然，留一法不受随机样本划分方式的影响，因为 $m$ 个样本只有唯一的方式划分为 $m$ 个子集——每个子集包含一个样本；留一法使用的训练集与初始数据集相比只少了一个样本，这就使得在绝大多数情况下，留一法中被实际评估的模型与期望评估的用 $D$ 训练出的模型很相似。因此，留一法的评估结果往往被认为比较准确。</p><p>然而，留一法也有其缺陷：在数据集比较大时，训练 $m$ 个模型的计算开销可能是难以忍受的（例如数据集包含 1 百万个样本，则需训练 1 百万个模型)，而这还是在未考虑算法调参的情况下。另外，留一法的估计结果也未必永远比其他评估方法准确；“没有免费的午餐”定理对实验评估方法同样适用。</p><h3 id=223-自助法>2.2.3 自助法</h3><p>自助法的主要步骤是，给定包含 $m$ 个样本的数据集 $D$，我们对它采样产生数据集 $D^{&rsquo;}$：每次随机从 $D$ 中挑选一个样本，将其拷贝放入 $D^{&rsquo;}$，然后再将该样本放回初始数据集 $D$ 中，使得该样本在下次采样时仍有可能被采到；这个过程重复执行 $m$ 次后，我们就得到了包含 $m$ 个样本的数据集 $D^{&rsquo;}$，这就是自助采样的结果。显然，$D$ 中有一部分样本会在 $D^{&rsquo;}$中多次出现，而另一部分样本不出现。可以做一个简单的估计，样本在 $m$ 次采样中始终不被采到的概率是 $(1 - \frac{1}{m})^m$，取极限得到</p><p>$$ \lim_{m \rightarrow \infty } (1 - \frac{1}{m})^m = \frac{1}{e} \approx 0.368 $$</p><p>即通过自助采样，初始数据集 $D$ 中约有 36.8% 的样本未出现在采样数据集 $D^{&rsquo;}$ 中。于是我们可将 $D^{&rsquo;}$ 用作训练集, $D$ \ $D^{&rsquo;}$ 用作测试集；这样，实际评估的模型与期望评估的模型都使用 $m$ 个训练样本，而我们仍有数据总量约 1/3 的、没在训练集中出现的样本用于测试。这样的测试结果，亦称“包外估计”(out-of-bag estimate)。</p><p>自助法在数据集较小、难以有效划分训练/测试集时很有用；此外，自助法能从初始数据集中产生多个不同的训练集；这对集成学习等方法有很大的好处。然而，自助法产生的数据集改变了初始数据集的分布，这会引入估计偏差。因此，在初始数据量足够时，留出法和交叉验证法更常用一些。</p><h2 id=23-性能度量>2.3 性能度量</h2><p>在预测任务中，给定样例集 $D = \{ (x_1, y_1), (x_2, y_2), \dots , (x_m, y_m) \} $ ，其中 $y_i$ 是 $x_i$ 的真实标记。要评估学习器 $f$ 的性能，就要把学习器预测结果 $f(x)$ 与真实标记 $y$ 进行比较。</p><p>回归任务最常用的性能度量是”均方误差“（mean squared error），即 Loss function</p><p>$$ L(f) = E(f; D) = \frac{1}{m} \sum_{i=1}^{m}(f(x_i) - y_i)^2 $$</p><p>更一般的，对于数据分布 $\mathcal{D}$ 和概率密度函数 $p(\cdot)$，均方误差可描述为</p><p>$$ L(f) = E(f; D) = \int_{x\sim D}^{}(f(x) - y)^2 p(x)dx $$</p><p>则最优学习器 $f^*$ 可以表示为</p><p>$$ f^* = arg \min_f L(f) $$</p><h3 id=231-错误率与精度>2.3.1 错误率与精度</h3><p>错误率和精度，这是分类任务中最常用的两种性能度量，既适用于二分类任务，也适用于多分类任务。错误率是分类错误的样本数占样本总数的比例，精度则是分类正确的样本数占样本总数的比例。对样例集 $D$，分类错误率定义为</p><p>$$ E(f; D) = \frac{1}{m} \sum_{i=1}^{m} \mathbb I (f(x_i) \neq y_i) $$</p><p>精度定义为</p><p>$$ acc(f; D) = \frac{1}{m} \sum_{i=1}^{m} \mathbb I (f(x_i) = y_i) \\ = 1 - E(f; D) $$</p><p>更一般的，对于数据分布 $\mathcal{D}$ 和概率密度函数 $p(\cdot)$，错误率与精度可分别描述为</p><p>$$ E(f; D) = \int_{x\sim D}^{}\mathbb I (f(x) \neq y) p(x)dx $$</p><p>$$ acc(f; D) = \int_{x\sim D}^{}\mathbb I (f(x) = y) p(x)dx \\ = 1 - E(f; D)$$</p><h3 id=232-查准率查全率与-f1-度量>2.3.2 查准率、查全率与 F1 度量</h3><p>错误率和精度虽常用，但并不能满足所有任务需求。以西瓜问题为例，假定瓜农拉来一车西瓜，我们用训练好的模型对这些西瓜进行判别，显然，错误率衡量了有多少比例的瓜被判别错误。但是若我们关心的是“挑出的西瓜中有多少。比例是好瓜”，或者“所有好瓜中有多少比例被挑了出来”，那么错误率显然就不够用了，这时需要使用其他的性能度量。</p><p>类似的需求在信息检索、Web 搜索等应用中经常出现，例如在信息检索中，我们经常会关心“检索出的信息中有多少比例是用户感兴趣的”，“用户感兴趣的信息中有多少被检索出来了”。“查准率”（precision）与”查全率“（recall）是更为适用于此类需求的性能度量。</p><p>对于二分类问题，可将样例根据其真实类别与学习器预测类别的组合划分为真正例（true positive）、假正例（false positive）、真反例（true negative）、假反例（false negative）四种情形，令 TP、FP、TN、FN 分别表示其对应的样例数，则显然有 TP + FP + TN + FN = 样例总数。分类结果的”混淆矩阵“（confusion matrix）如下表所示。</p><p><img src=https://cdn.jsdelivr.net/gh/jinggqu/blog_images@main/20201225161654.png loading=lazy alt=20201225161654></p><p>查准率 $P$ 与查全率 $R$ 分别定义为</p><p>$$ P = \frac{TP}{TP + FP} $$</p><p>$$ R = \frac{TP}{TP + FN} $$</p><p>查准率和查全率是一对矛盾的度量。一般来说，查准率高时，查全率往往偏低；而查全率高时，查准率往往偏低。
我们可以这样理解查准率与查全率：</p><blockquote><p>查准率：预测为正例的结果中，真·正例所占的比例；<br>查全率：所有正例中，预测为正例所占的比例。</p></blockquote><p>在很多情形下，我们可根据学习器的预测结果对样例进行排序，排在前面的是学习器认为”最可能“是正例的样本，排在最后的则是学习器认为”最不可能“是正例的样本。按此顺序逐个把样本作为正例进行预测，则每次可以计算出当前的查全率、查准率。以查准率为纵轴、查全率为横轴作图，就得到了查准率-查全率曲线，简称”P-R 曲线“，显示该曲线的图称为”P-R 图“。下图是”P-R 图“的一个示例。</p><p><img src=https://cdn.jsdelivr.net/gh/jinggqu/blog_images@main/20201225164329.png loading=lazy alt=20201225164329></p><p>P-R 图直观地显示出学习器在样本总体上的查全率、查准率在进行比较时，若一个学习器的 P-R 曲线被另一个学习器的曲线完全”包住“，则可断言后者的性能优于前者，例如上图中学习器 A 的性能优于学习器 C；如果两个学习器的 P-R 曲线发生了交叉，例如上图中的 A 与 B，则难以一般性地断言两者孰优孰劣,只能在具体的查准率或查全率条件下进行比较。然而，在很多情形下，人们往往仍希望把学习器 A 与 B 比出个高低。这时一个比较合理的判据是比较 P-R 曲线下面积的大小，它在一定程度上表征了学习器在查准率和查全率上取得相对”双高“的比例。但这个值不太容易估算，因此，人们设计了一些综合考虑查准率、查全率的性能度量。</p><p>“平衡点”（Break-Event Point，简称 BEP）就是这样一个度量，它是“查准率=查全率”时的取值，例如上图中学习器 C 的 BEP 是 0.64，而基于 BEP 的比较，可认为学习器 A 优于 B。</p><h3 id=233-roc-与-auc>2.3.3 ROC 与 AUC</h3><p>与 2.3.2 节中介绍的 P-R 曲线相似，我们根据学习器的预测结果对样例进行排序，按此顺序逐个把样本作为正例进行预测，每次计算出两个重要量的值，分别以它们为横、纵坐标作图，就得到了“ROC 曲线”。与 P-R 曲线使用查准率、查全率为纵、横轴不同，ROC 曲线的纵轴是“真正例率”（True Positive Rate, 简称 TPR）,横轴是“假正例率”（False PositiveRate，简称 FPR），基于上文中相关表格中的符号，两者分别定义为</p><p>$$ TPR = \frac{TP}{TP + FN} $$</p><p>$$ FPR = \frac{FP}{TN + FP} $$</p><h3 id=234-代价敏感错误率与代价曲线>2.3.4 代价敏感错误率与代价曲线</h3><p>为权衡不同类型错误所造成的不同损失，可为错误赋予”非均等代价“（unequal cost）。</p><p>以二分类任务为例，我们可根据任务的领域知识设定一个”代价矩阵“（cost matrix），如下表所示，其中 $cost_{ij}$ 表示将第 $i$ 类样本预测为第 $j$ 类样本的代价；一般来说，$cost_{ii} = 0$；若将第 0 类判别为第 1 类所造成的损失更大，则 $cost_{01} > cost_{10}$；损失程度相差越大，$cost_{01}$ 与 $cost_{10}$ 值的差别越大。</p><p><img src=https://cdn.jsdelivr.net/gh/jinggqu/blog_images@main/20201225171957.png loading=lazy alt=20201225171957></p><p>回顾前面介绍的一些性能度量可看出，它们大都隐式地假设了均等代价，并没有考虑不同错误会造成不同的后果。在非均等代价下，我们所希望的不再是简单地最小化错误次数，而是希望最小化“总体代价”（total cost）。若将上表中的第 0 类作为正类、第 1 类作为反类，令 $D^+$ 与 $D^-$ 分别代表样例集 $D$ 的正例子集和反例子集，则“代价敏感”（cost-sensitive）错误率为</p><p>$$ E(f; D; cost) = \frac{1}{m} (\sum_{x_i \in D^+} \mathbb I (f(x_i) \neq y_i) \times cost_{01} \\ + \sum_{x_i \in D^-} \mathbb I (f(x_i) \neq y_i) \times cost_{10}) $$</p><p>类似的，可给出基于分布定义的代价敏感错误率，以及其他一些性能度量如精度的代价敏感版本。若令 $cost_{ij}$ 中的 $i$、$j$ 取值不限于 0、1, 则可定义出多分类任务的代价敏感性能度量。</p><h1 id=参考文献>参考文献</h1><ol><li><a class=link href=https://zh.wikipedia.org/wiki/%E9%81%8E%E9%81%A9 target=_blank rel=noopener>过拟合-维基百科</a></li><li><a class=link href=https://zh.wikipedia.org/wiki/%E5%88%86%E5%B1%82%E6%8A%BD%E6%A0%B7 target=_blank rel=noopener>分层抽样</a></li><li><a class=link href=https://datawhalechina.github.io/leeml-notes/ target=_blank rel=noopener>李宏毅机器学习笔记(LeeML-Notes)</a></li></ol></section><footer class=article-footer><section class=article-copyright><svg xmlns="http://www.w3.org/2000/svg" class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span></section></footer><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/katex.min.css integrity="sha256-J+iAE0sgH8QSz9hpcDxXIftnj65JEZgNhGcgReTTK9s=" crossorigin=anonymous><script src=https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/katex.min.js integrity="sha256-InsNdER1b2xUewP+pKCUJpkhiqwHgqiPXDlIk7GzBu4=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/katex@0.15.6/dist/contrib/auto-render.min.js integrity="sha256-y39Mpg7V3D4lhBX4x6O0bUqTV4pSrfgwEfGKfxkOdgI=" crossorigin=anonymous defer></script><script>window.addEventListener("DOMContentLoaded",()=>{renderMathInElement(document.querySelector(`.article-content`),{delimiters:[{left:"$$",right:"$$",display:!0},{left:"$",right:"$",display:!1},{left:"\\(",right:"\\)",display:!1},{left:"\\[",right:"\\]",display:!0}],ignoredClasses:["gist"]})})</script></article><aside class=related-content--wrapper><h2 class=section-title>Related content</h2><div class=related-content><div class="flex article-list--tile"><article><a href=/posts/machine-learning-note-4/><div class=article-details><h2 class=article-title>《机器学习》笔记（第五章）</h2></div></a></article><article><a href=/posts/machine-learning-note-3/><div class=article-details><h2 class=article-title>《机器学习》笔记（第四章）</h2></div></a></article><article><a href=/posts/sae-2/><div class=article-details><h2 class=article-title>SAE 入门（二）——基于 tiny_dnn 的手写数字重建</h2></div></a></article><article><a href=/posts/sae-1/><div class=article-details><h2 class=article-title>SAE 入门（一）</h2></div></a></article><article><a href=/posts/machine-learning-note-2/><div class=article-details><h2 class=article-title>《机器学习》笔记（第三章）</h2></div></a></article></div></div></aside><script src=https://giscus.app/client.js data-repo=jinggqu/jinggqu.github.io data-repo-id="MDEwOlJlcG9zaXRvcnkxNDkyMTI2MDk=" data-category=Announcements data-category-id=DIC_kwDOCOTNwc4Ca4Al data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=light data-lang=en crossorigin=anonymous async></script><script>function setGiscusTheme(e){let t=document.querySelector("iframe.giscus-frame");t&&t.contentWindow.postMessage({giscus:{setConfig:{theme:e}}},"https://giscus.app")}(function(){addEventListener("message",t=>{if(event.origin!=="https://giscus.app")return;e()}),window.addEventListener("onColorSchemeChange",e);function e(){setGiscusTheme(document.documentElement.dataset.scheme==="light"?"light":"dark")}})()</script><footer class=site-footer><section class=copyright>&copy;
2018 -
2024 Anthony's blog</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.20.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>